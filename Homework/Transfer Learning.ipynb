{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作業想比較使用原本的整個CNN_layers來進行遷移學習及使用一部分CNN_layers進行的差別"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.載入套件及資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Layers for FNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "# Layers for CNN\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "# For data preprocessing\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR 10\n",
    "(X_train, y_train0), (X_test, y_test0) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize the range of featurs\n",
    "X_train = X_train / X_train.max()\n",
    "X_test = X_test / X_test.max()\n",
    "\n",
    "# One-hot encoding\n",
    "y_train = to_categorical(y_train0, 10)\n",
    "y_test = to_categorical(y_test0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(X_train.shape[0])\n",
    "X_sample = X_train[idx]\n",
    "y_sample = y_train0[idx].squeeze()\n",
    "\n",
    "plt.imshow(X_sample)\n",
    "plt.title(name_list[y_sample])\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.使用第二個使用Sequential建立模型的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_layers_1 = [Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', name='Conv_1_1'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(128, (3, 3), padding='same', activation='relu', name='Conv_2_1'),\n",
    "              MaxPool2D()]\n",
    "CNN_layers_2 = [Conv2D(512, (3, 3), padding='same', activation='relu', name='Conv_3_2'),\n",
    "              GlobalAveragePooling2D()]\n",
    "\n",
    "FC_layers = [Dense(units=256, activation='relu'),\n",
    "             Dense(units=10, activation='softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x1aab304e208>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1aab304e4c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1aab304e648>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1aab304e8c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1aab304e1c8>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x1aab3043208>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1aab304ec48>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1aab3043c08>]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_layers_1 + CNN_layers_2 + FC_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2_1 (Conv2D)            (None, 16, 16, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv_3_2 (Conv2D)            (None, 8, 8, 512)         590336    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_11  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 762,122\n",
      "Trainable params: 762,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(CNN_layers_1+CNN_layers_2+FC_layers)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 編譯模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(),\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "50000/50000 [==============================] - 11s 227us/sample - loss: 1.1605 - categorical_accuracy: 0.5807 - val_loss: 1.1767 - val_categorical_accuracy: 0.5752\n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 10s 207us/sample - loss: 1.0770 - categorical_accuracy: 0.6135 - val_loss: 1.1260 - val_categorical_accuracy: 0.5952\n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 10s 209us/sample - loss: 1.0104 - categorical_accuracy: 0.6395 - val_loss: 1.0205 - val_categorical_accuracy: 0.6437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1aac0526208>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          batch_size=128, \n",
    "          epochs=3,\n",
    "          validation_data=(X_test, y_test)\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 8s 164us/sample - loss: 0.9888 - categorical_accuracy: 0.6518\n",
      "10000/10000 [==============================] - 2s 162us/sample - loss: 1.0205 - categorical_accuracy: 0.6437\n",
      "Train Accuracy: 65.17999768257141\n",
      "Test Accuracy: 64.37000036239624\n"
     ]
    }
   ],
   "source": [
    "score_train = model.evaluate(X_train, y_train)\n",
    "score_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CIFAR10_CNN.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x1aab304e208>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1aab304e4c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1aab304e648>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1aab304e8c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1aab304e1c8>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x1aab3043208>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1aab304ec48>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1aab3043c08>]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Layer Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR 100\n",
    "(U_train, v_train0), (U_test, v_test0) = datasets.cifar100.load_data()\n",
    "\n",
    "# Normalize the range of featurs\n",
    "U_train = U_train / U_train.max()\n",
    "U_test = U_test / U_test.max()\n",
    "\n",
    "# One-hot encoding\n",
    "v_train = to_categorical(v_train0, 100)\n",
    "v_test = to_categorical(v_test0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC_layers_CF100 = [Dense(units=256, activation='relu'),\n",
    "                   Dense(units=128, activation='relu'),\n",
    "                   Dense(units=100, activation='softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CF100v1 = Sequential(CNN_layers_1+CNN_layers_2+FC_layers_CF100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2_1 (Conv2D)            (None, 16, 16, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv_3_2 (Conv2D)            (None, 8, 8, 512)         590336    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_11  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 100)               12900     \n",
      "=================================================================\n",
      "Total params: 805,348\n",
      "Trainable params: 805,348\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_CF100v1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將借來的CNN_layers凍結"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in CNN_layers_1:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in CNN_layers_2:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 確定借來的部分確實Non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2_1 (Conv2D)            (None, 16, 16, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv_3_2 (Conv2D)            (None, 8, 8, 512)         590336    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_11  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 100)               12900     \n",
      "=================================================================\n",
      "Total params: 805,348\n",
      "Trainable params: 177,124\n",
      "Non-trainable params: 628,224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_CF100v1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 8s 159us/sample - loss: 3.6881 - categorical_accuracy: 0.1377 - val_loss: 3.2845 - val_categorical_accuracy: 0.2001\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 5s 109us/sample - loss: 3.1556 - categorical_accuracy: 0.2185 - val_loss: 3.0549 - val_categorical_accuracy: 0.2408\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 5s 109us/sample - loss: 2.9847 - categorical_accuracy: 0.2511 - val_loss: 2.9455 - val_categorical_accuracy: 0.2625\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 5s 108us/sample - loss: 2.8769 - categorical_accuracy: 0.2751 - val_loss: 2.8484 - val_categorical_accuracy: 0.2844\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 5s 110us/sample - loss: 2.7924 - categorical_accuracy: 0.2942 - val_loss: 2.7863 - val_categorical_accuracy: 0.2952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1aac0f312c8>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CF100v1.compile(loss='categorical_crossentropy', \n",
    "                    optimizer=Adam(),\n",
    "                    metrics=['categorical_accuracy'])\n",
    "\n",
    "model_CF100v1.fit(U_train, v_train,\n",
    "                batch_size=128, \n",
    "                epochs=5,\n",
    "                validation_data=(U_test, v_test)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 8s 159us/sample - loss: 0.9888 - categorical_accuracy: 0.6518\n",
      "10000/10000 [==============================] - 2s 154us/sample - loss: 1.0205 - categorical_accuracy: 0.6437\n",
      "Train Accuracy: 65.17999768257141\n",
      "Test Accuracy: 64.37000036239624\n"
     ]
    }
   ],
   "source": [
    "score_train = model.evaluate(X_train, y_train)\n",
    "score_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 此結果確實與第一次預測的相同(65/64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.若只凍結CNN_layer的一部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CF100v2 = Sequential(CNN_layers_1+CNN_layers_2+FC_layers_CF100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2_1 (Conv2D)            (None, 16, 16, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv_3_2 (Conv2D)            (None, 8, 8, 512)         590336    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_11  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 100)               12900     \n",
      "=================================================================\n",
      "Total params: 805,348\n",
      "Trainable params: 177,124\n",
      "Non-trainable params: 628,224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_CF100v1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 只將CNN_layers_1凍結"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in CNN_layers_1:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in CNN_layers_2:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2_1 (Conv2D)            (None, 16, 16, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv_3_2 (Conv2D)            (None, 8, 8, 512)         590336    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_11  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 100)               12900     \n",
      "=================================================================\n",
      "Total params: 805,348\n",
      "Trainable params: 767,460\n",
      "Non-trainable params: 37,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_CF100v2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 8s 169us/sample - loss: 2.7231 - categorical_accuracy: 0.3045 - val_loss: 2.6621 - val_categorical_accuracy: 0.3208\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 7s 146us/sample - loss: 2.5890 - categorical_accuracy: 0.3332 - val_loss: 2.6018 - val_categorical_accuracy: 0.3389\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 7s 147us/sample - loss: 2.4900 - categorical_accuracy: 0.3504 - val_loss: 2.5041 - val_categorical_accuracy: 0.3536\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 7s 147us/sample - loss: 2.4163 - categorical_accuracy: 0.3684 - val_loss: 2.4289 - val_categorical_accuracy: 0.3728\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 7s 147us/sample - loss: 2.3432 - categorical_accuracy: 0.3828 - val_loss: 2.4122 - val_categorical_accuracy: 0.3746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1aac16154c8>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CF100v2.compile(loss='categorical_crossentropy', \n",
    "                    optimizer=Adam(),\n",
    "                    metrics=['categorical_accuracy'])\n",
    "\n",
    "model_CF100v2.fit(U_train, v_train,\n",
    "                batch_size=128, \n",
    "                epochs=5,\n",
    "                validation_data=(U_test, v_test)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 8s 164us/sample - loss: 1.0861 - categorical_accuracy: 0.6269 - loss: 1.0860 - categorical_accuracy\n",
      "10000/10000 [==============================] - 2s 163us/sample - loss: 1.1115 - categorical_accuracy: 0.6180 - loss: 1.1067 - categori\n",
      "Train Accuracy: 62.69000172615051\n",
      "Test Accuracy: 61.799997091293335\n"
     ]
    }
   ],
   "source": [
    "score_train = model.evaluate(X_train, y_train)\n",
    "score_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得知準確度確實會不一樣 且準確度低於將CNN_layers_1和CNN_layers_2都凍結住的model_CF100v1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
